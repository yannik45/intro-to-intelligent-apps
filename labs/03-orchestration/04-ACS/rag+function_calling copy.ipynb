{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: fg: no job control\n",
      "/bin/bash: line 1: fg: no job control\n",
      "/bin/bash: line 1: fg: no job control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: fg: no job control\n",
      "Requirement already satisfied: langchainhub in /usr/local/python/3.11.8/lib/python3.11/site-packages (0.1.15)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/vscode/.local/lib/python3.11/site-packages (from langchainhub) (2.31.0)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/python/3.11.8/lib/python3.11/site-packages (from langchainhub) (2.31.0.20240218)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vscode/.local/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.local/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!%pip install --upgrade langchain\n",
    "!%pip install --upgrade langchain-openai\n",
    "!%pip install -qU langchain-core langchain-openai\n",
    "!%pip install --upgrade openai\n",
    "!pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This lab exercise will use the following values:\n",
      "Azure OpenAI Endpoint: https://oai-mtpchatbot-dev-frcent-001.openai.azure.com/\n",
      "Azure AI Search: srch-mtpchatbot-dev-frcent-001\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"This lab exercise will use the following values:\")\n",
    "    print(\"Azure OpenAI Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "    print(\"Azure AI Search: \" + os.getenv(\"AZURE_AI_SEARCH_SERVICE_NAME\"))\n",
    "else: \n",
    "    print(\"No file .env found\")\n",
    "\n",
    "azure_openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai_api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "azure_openai_completion_deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "azure_openai_embedding_deployment_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "azure_ai_search_name = os.getenv(\"AZURE_AI_SEARCH_SERVICE_NAME\")\n",
    "azure_ai_search_endpoint = os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\")\n",
    "azure_ai_search_index_name = os.getenv(\"AZURE_AI_SEARCH_INDEX_NAME\")\n",
    "azure_ai_search_api_key = os.getenv(\"AZURE_AI_SEARCH_API_KEY\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "azure_openai_embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"),\n",
    "    openai_api_version = os.getenv(\"OPENAI_EMBEDDING_API_VERSION\"),\n",
    "    model= os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "from azure.search.documents.models import (\n",
    "    VectorizedQuery\n",
    ")\n",
    "\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.tools import MoveFileTool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from openai import AzureOpenAI\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name: str = \"mtp-chatbot-hybrid-search-plus-weblate-plus-websites\"\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\"),\n",
    "    azure_search_key=os.getenv(\"AZURE_AI_SEARCH_API_KEY\"),\n",
    "    index_name=index_name,\n",
    "    embedding_function=azure_openai_embeddings.embed_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "Schritt 1: \n",
      "Registrieren Sie sich für MyTruckPoint. \n",
      "Anschließend erscheint eine Schaltfläche zur\n",
      "Registrierung von TruckLive. \n",
      "Um den Prozess zu beginnen, klicken Sie bitte\n",
      "auf „Weiter“. (     )1\n",
      "\n",
      "TRUCKLIVE: KURZANLEITUNG VERTRAGSABSCHLUSS\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "Schritt 2:\n",
      "Stimmen Sie dem Daimler Rahmenvertrag\n",
      "für digitale Dienste zu. (     )\n",
      "Klicken Sie anschließend auf „Bestätigen\n",
      "und Weiter“. (     )3\n",
      "\n",
      "2\n",
      "\n",
      "TRUCKLIVE: KURZANLEITUNG VERTRAGSABSCHLUSS\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "\n",
      "Schritt 3:\n",
      "Stimmen Sie dem TruckLive Vertrag zu. (     )\n",
      "Klicken Sie anschließend auf „Bestätigen\n",
      "und Weiter“. (     )\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "TRUCKLIVE: KURZANLEITUNG VERTRAGSABSCHLUSS\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "Schritt 4:\n",
      "Definieren Sie einen Zeitpunkt, ab dem TruckLive\n",
      "für zukünftige Fahrzeuge aktiviert werden soll. (     )\n",
      "Wählen Sie danach eine Kontaktperson aus dem\n",
      "eigenen Unternehmen aus, welche die Meldungen \n",
      "zu TruckLive bekommen soll. (     ) \n",
      "Abschließend klicken Sie auf „Bestätigen“. (     )\n",
      "\n",
      "Herzlichen Glückwunsch! \n",
      "TruckLive ist nun aktiviert und all Ihre Neufahrzeuge\n",
      "erhalten TruckLive (inkl. Live Traffic) automatisch ab\n",
      "Ihrem gewünschten Aktivierungszeitpunkt.\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "6\n",
      "\n",
      "TRUCKLIVE: KURZANLEITUNG VERTRAGSABSCHLUSS\n"
     ]
    }
   ],
   "source": [
    "# Perform a similarity search\n",
    "results = vector_store.similarity_search(\n",
    "    query=\"Wie schließe ich einen TruckLive Vertrag ab?\",\n",
    "    k=3,\n",
    "    search_type=\"hybrid\",\n",
    ")\n",
    "print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AzureOpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Bringing it together: implement RAG\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mAzureOpenAI\u001b[49m(\n\u001b[1;32m      5\u001b[0m     azure_endpoint\u001b[38;5;241m=\u001b[39mazure_openai_endpoint,  \u001b[38;5;66;03m# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mazure_openai_api_key,  \u001b[38;5;66;03m# The API key for your Azure OpenAI resource.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     api_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-12-01-preview\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# This version supports function calling\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m tools \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     {\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     }\n\u001b[1;32m     28\u001b[0m ]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Ask the question\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# function for AI Search query\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AzureOpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "# Bringing it together: implement RAG\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=azure_openai_endpoint,  # The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "    api_key=azure_openai_api_key,  # The API key for your Azure OpenAI resource.\n",
    "    api_version=\"2023-12-01-preview\",  # This version supports function calling\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"query_information\",\n",
    "            \"description\": \"Retrieve information about My TruckPoint, TruckLive and everything related from Azure AI search index\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The query string to search for relevant data about My TruckPoint and everything\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Ask the question\n",
    "\n",
    "# function for AI Search query\n",
    "def query_information(messages):\n",
    "    query = messages[1][\"content\"]\n",
    "    print('AI Search started')\n",
    "    \n",
    "    results = list(vector_store.similarity_search(\n",
    "    query=query,\n",
    "    k=3,\n",
    "    search_type=\"hybrid\",\n",
    "    ))\n",
    "\n",
    "    return results[0].page_content\n",
    "\n",
    "def run_conversation(messages, tools):\n",
    "\n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_completion_deployment_name,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice={\"type\": \"function\", \"function\": {\"name\": \"query_information\"}},\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # Step 2: check if the model wants to call a function\n",
    "    if tool_calls:\n",
    "        print(\"Recommended Function call:\")\n",
    "        print(response_message.tool_calls[0])\n",
    "\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "       \n",
    "        available_functions = {\"query_information\": query_information}\n",
    "\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            #print(tool_call.function.arguments)\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(**function_args)\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            ) \n",
    "        second_response = client.chat.completions.create(\n",
    "            model=azure_openai_completion_deployment_name,\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        return second_response.model_dump_json(indent=2)\n",
    "    else:\n",
    "        return response\n",
    "       \n",
    "\n",
    "system_message =  \"\"\"   \n",
    "    If the requested information is not available in the retrieved data, please answer with something like that: \n",
    "    I'm sorry, but this question about XY is out of the scope of my knowledge as I am an AI assistent designed to provide information related to My TruckPoint. \n",
    "    If you have questions to the usage of My TruckPoint, TruckLive or other related topics, I would be happy to assist you.\n",
    "    If the user asks for a term that you find SIMILIAR but NOT EQUAL in your source data, ask the user first whether he really means this term. If the user confirms, explain the term. If the user doesn't confirm, tell that you can unfortunately not help on this and ask for a new question.\n",
    "    \n",
    "    You are a friendly and professional support chatbot for customers of the application MyTruckpoint. \n",
    "    Your task is to answer questions about the use of MyTruckpoint and all associated components.\n",
    "    Only tell that it is not available in his country.\n",
    "    Your answer shouldn't be longer then round about 150 words. If the user asks a question in language XY, answer to him in language XY.\n",
    "\"\"\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Was ist My TruckPoint?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(messages[1][\"content\"])\n",
    "available_functions = {\"query_information\": query_information}\n",
    "\n",
    "result = run_conversation(messages, tools)\n",
    "\n",
    "print(\"Final response:\")\n",
    "print(result.model_dump_json(indent=2))\n",
    "\n",
    "# Build the Prompt and Execute against the Azure OpenAI to get the completion\n",
    "#chain = LLMChain(llm=model_with_tools, prompt=prompt, verbose=False)\n",
    "#response = chain.invoke({\"original_question\": query, \"search_results\": results})\n",
    "#print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
