{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: fg: no job control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: fg: no job control\n",
      "/bin/bash: line 1: fg: no job control\n",
      "/bin/bash: line 1: fg: no job control\n"
     ]
    }
   ],
   "source": [
    "!%pip install --upgrade langchain\n",
    "!%pip install --upgrade langchain-openai\n",
    "!%pip install -qU langchain-core langchain-openai\n",
    "!%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This lab exercise will use the following values:\n",
      "Azure OpenAI Endpoint: https://oai-mtpchatbot-dev-frcent-001.openai.azure.com/\n",
      "Azure AI Search: srch-mtpchatbot-dev-frcent-001\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"This lab exercise will use the following values:\")\n",
    "    print(\"Azure OpenAI Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "    print(\"Azure AI Search: \" + os.getenv(\"AZURE_AI_SEARCH_SERVICE_NAME\"))\n",
    "else: \n",
    "    print(\"No file .env found\")\n",
    "\n",
    "azure_openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai_api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "azure_openai_completion_deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "azure_openai_embedding_deployment_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "azure_ai_search_name = os.getenv(\"AZURE_AI_SEARCH_SERVICE_NAME\")\n",
    "azure_ai_search_endpoint = os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\")\n",
    "azure_ai_search_index_name = os.getenv(\"AZURE_AI_SEARCH_INDEX_NAME\")\n",
    "azure_ai_search_api_key = os.getenv(\"AZURE_AI_SEARCH_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "azure_openai_embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"),\n",
    "    openai_api_version = os.getenv(\"OPENAI_EMBEDDING_API_VERSION\"),\n",
    "    model= os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "index_name: str = \"mtp-chatbot-hybrid-search-plus-weblate-plus-websites\"\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\"),\n",
    "    azure_search_key=os.getenv(\"AZURE_AI_SEARCH_API_KEY\"),\n",
    "    index_name=index_name,\n",
    "    embedding_function=azure_openai_embeddings.embed_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "Schritt 1: \n",
      "Registrieren Sie sich für MyTruckPoint. \n",
      "Anschließend erscheint eine Schaltfläche zur\n",
      "Registrierung von TruckLive. \n",
      "Um den Prozess zu beginnen, klicken Sie bitte\n",
      "auf „Weiter“. (     )1\n",
      "\n",
      "TRUCKLIVE: KURZANLEITUNG VERTRAGSABSCHLUSS\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "Schritt 2:\n",
      "Stimmen Sie dem Daimler Rahmenvertrag\n",
      "für digitale Dienste zu. (     )\n",
      "Klicken Sie anschließend auf „Bestätigen\n",
      "und Weiter“. (     )3\n",
      "\n",
      "2\n",
      "\n",
      "TRUCKLIVE: KURZANLEITUNG VERTRAGSABSCHLUSS\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "\n",
      "Schritt 3:\n",
      "Stimmen Sie dem TruckLive Vertrag zu. (     )\n",
      "Klicken Sie anschließend auf „Bestätigen\n",
      "und Weiter“. (     )\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "TRUCKLIVE: KURZANLEITUNG VERTRAGSABSCHLUSS\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "Schritt 4:\n",
      "Definieren Sie einen Zeitpunkt, ab dem TruckLive\n",
      "für zukünftige Fahrzeuge aktiviert werden soll. (     )\n",
      "Wählen Sie danach eine Kontaktperson aus dem\n",
      "eigenen Unternehmen aus, welche die Meldungen \n",
      "zu TruckLive bekommen soll. (     ) \n",
      "Abschließend klicken Sie auf „Bestätigen“. (     )\n",
      "\n",
      "Herzlichen Glückwunsch! \n",
      "TruckLive ist nun aktiviert und all Ihre Neufahrzeuge\n",
      "erhalten TruckLive (inkl. Live Traffic) automatisch ab\n",
      "Ihrem gewünschten Aktivierungszeitpunkt.\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "6\n",
      "\n",
      "TRUCKLIVE: KURZANLEITUNG VERTRAGSABSCHLUSS\n"
     ]
    }
   ],
   "source": [
    "# Perform a similarity search testwise\n",
    "results = vector_store.similarity_search(\n",
    "    query=\"Wie schließe ich einen TruckLive Vertrag ab?\",\n",
    "    k=3, # forgot what this was -> k nearest neighbour?\n",
    "    search_type=\"hybrid\",\n",
    "    # adjust relevance with score_threshold= xy,\n",
    ")\n",
    "print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My TruckPoint is a digital customer portal for Mercedes-Benz Trucks that allows users to manage their vehicles, services, contracts, and information in one place. It supports communication with the user's sales representative and helps with daily tasks. My TruckPoint can be accessed from smartphones, tablets, and computers/laptops using all standard web browsers. The user manager has the option to invite other users from the same company to use My TruckPoint, and the role and associated rights for using My TruckPoint are assigned and managed by the respective user manager. The managing director is the only one allowed to change company data, and only the user personally can change their user data. My TruckPoint also offers support for Fleetboard hardware and activation, adding service contracts to vehicles, vehicle management, and integrating third-party products. However, if the user's requested information is not available in the retrieved data, the AI assistant will inform the user that it is out of the scope of its knowledge.\n"
     ]
    }
   ],
   "source": [
    "# Bringing it together\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "azure_openai = AzureChatOpenAI(\n",
    "    azure_deployment = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    ")\n",
    "\n",
    "\n",
    "# Ask the question\n",
    "query = \"What can you tell me about My TruckPoint?\"\n",
    "\n",
    "# Create a prompt template with variables, note the curly braces\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"original_question\",\"search_results\"],\n",
    "    template=\"\"\"\n",
    "    \n",
    "\n",
    "    Question: {original_question}\n",
    "   \n",
    "\n",
    "    If the requested information is not available in the retrieved data, please answer with something like that: \n",
    "    I'm sorry, but this question about XY is out of the scope of my knowledge as I am an AI assistent designed to provide information related to My TruckPoint. \n",
    "    If you have questions to the usage of My TruckPoint, TruckLive or other related topics, I would be happy to assist you.\n",
    "    If the user asks for a term that you find SIMILIAR but NOT EQUAL in your source data, ask the user first whether he really means this term. If the user confirms, explain the term. If the user doesn't confirm, tell that you can unfortunately not help on this and ask for a new question.\n",
    "    \n",
    "    You are a friendly and professional support chatbot for customers of the application MyTruckpoint. \n",
    "    Your task is to answer questions about the use of MyTruckpoint and all associated components.\n",
    "    Only tell that it is not available in his country.\n",
    "    Your answer shouldn't be longer then round about 150 words. If the user asks a question in language XY, answer to him in language XY.\n",
    "    \n",
    "    Search Results: {search_results}\n",
    "   \n",
    "   \n",
    "    \"\"\",\n",
    "\n",
    "    # in der Vorlage war das Schema Question , Systemprompt, Search Results keine Ahnung ob das einen Unterschied macht\n",
    ")\n",
    "\n",
    "#vector = VectorizedQuery(vector=azure_openai_embeddings.embed_query(query), k_nearest_neighbors=5, fields=\"vector\")\n",
    "\n",
    "#see previous cells\n",
    "results = list(vector_store.similarity_search(\n",
    "    query=query,\n",
    "    k=3,\n",
    "    search_type=\"hybrid\",\n",
    "))\n",
    "\n",
    "# Build the Prompt and Execute against the Azure OpenAI to get the completion\n",
    "chain = LLMChain(llm=azure_openai, prompt=prompt, verbose=False)\n",
    "response = chain.invoke({\"original_question\": query, \"search_results\": results})\n",
    "print(response['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
